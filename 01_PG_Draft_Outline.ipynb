{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- This is a summary program based on Langchain's short course 'Chat with your data'\n",
    "- A simplified version that uses PDF file only to show how a document is transformed\n",
    "    - Load multiple PDF files\n",
    "    - Split loaded files into smaller chunks\n",
    "    - Chunks are embedded using OpenAI embedding\n",
    "    - Store these embeddings in a Vector database (ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My secret key is: 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.\n"
     ]
    }
   ],
   "source": [
    "# Basic setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import openai\n",
    "\n",
    "from dotenv import  load_dotenv\n",
    "\n",
    "load_dotenv() # read local .env file\n",
    "\n",
    "# openai_api_key='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'\n",
    "\n",
    "openai.api_key=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# openai.api_key  = os.environ[OPENAI_API_KEY]\n",
    "\n",
    "def myEnvironment():\n",
    "    # print(f'My id is: {my_id}.')\n",
    "    print(f'My secret key is: {openai.api_key}.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    myEnvironment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langchain provides a <loader> module for loading both structured and unstructured data sources. Here we are using PyPDF loader for uploading sample PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "PyPDFLoader(\"docs1/MachineLearning-Lecture01.pdf\"),\n",
    "PyPDFLoader(\"docs1/MachineLearning-Lecture02.pdf\"),\n",
    "PyPDFLoader(\"docs1/MachineLearning-Lecture03.pdf\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find out how many pages have been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Break uploaded PDFs into smaller chunks. We need to define, chunk size, chunk overlap. Langchain provides RecursiveCharacterTextSplitter and Character text splitter. Major difference is \n",
    "    - Recursive character text splitter - is preferred for Generic text splitting\n",
    "    - Character text splitter splits on new line character. If you set the character on space it will be split as recursive CTS\n",
    "    - double new line separater between paragraphs\n",
    "    - Recursive Character text splitters has other separators as well such /n/n, /n, \" \", \"\" by default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 120\n",
    "chunk_overlap = 10\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "\n",
    "splits = r_splitter.split_documents(\n",
    "\n",
    "docs\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore these chucks\n",
    "    - How many chunks?\n",
    "    - What is inside them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1889"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of chunks\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content='learning class. So what I wanna do today is ju st spend a little time going over the logistics', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content=\"of the class, and then we'll start to  talk a bit about machine learning.\", metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content=\"By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so\", metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content=\"I personally work in machine learning, and I' ve worked on it for about 15 years now, and\", metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content='I actually think that machine learning is th e most exciting field of all the computer', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content=\"sciences. So I'm actually always excited about  teaching this class. Sometimes I actually\", metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content='think that machine learning is not only the most exciting thin g in computer science, but', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content='the most exciting thing in all of human e ndeavor, so maybe a little bias there.', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0}),\n",
       " Document(page_content='I also want to introduce the TAs, who are all graduate students doing research in or', metadata={'source': 'docs1/MachineLearning-Lecture01.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the text of a chunk\n",
    "\n",
    "splits[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand Embeddings\n",
    "    - Use OpenAI embedding\n",
    "    - Understand similarity between words and sentences\n",
    "    - Use `dot` product to compare embeddings, higher score is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_1 = \"Apple\",\n",
    "embedding_2 = \"car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0028599445902576914, -0.005424751648017928, -0.01598874169942126, -0.021673343066195377, -0.021006076492248848, 0.027409271484722164, -0.007866050426361114, -0.005344551267009154, -0.003952273323249115, -0.0062492115089087695]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedding_1, embedding_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487800690436125"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7966507280236204"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding_2, embedding_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636250274290804"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding_1, embedding_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.870826933839829"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding_5, embedding_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup a vector database to store all splits after embedding them\n",
    "    - Run `pip install chromadb`\n",
    "    - Need to create a directory where all splits will be stored and pass it as persist_path\n",
    "    - Need to pass embedding information, we are using OpenAI embeddings\n",
    "    - All splits as document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(splits, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_directory = 'docs1/chroma/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any existing directory\n",
    "!rm -rf ./docs1/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "# default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected EmbeddingFunction.__call__ to have the following signature: odict_keys(['self', 'input']), got odict_keys(['self', 'args', 'kwargs'])\nPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\nPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vectordb \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     splits,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     embedding\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:684\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    683\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 684\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    685\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    686\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    687\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    688\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    689\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    690\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    691\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    692\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    693\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    694\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    695\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:620\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    589\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    600\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    601\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    621\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    622\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    623\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    624\u001b[0m         client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    625\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    626\u001b[0m         collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    627\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m     \u001b[39mif\u001b[39;00m ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m         ids \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid1()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:125\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persist_directory \u001b[39m=\u001b[39m (\n\u001b[1;32m    121\u001b[0m         _client_settings\u001b[39m.\u001b[39mpersist_directory \u001b[39mor\u001b[39;00m persist_directory\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[0;32m--> 125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mget_or_create_collection(\n\u001b[1;32m    126\u001b[0m     name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    127\u001b[0m     embedding_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    130\u001b[0m     metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverride_relevance_score_fn \u001b[39m=\u001b[39m relevance_score_fn\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:226\u001b[0m, in \u001b[0;36mClient.get_or_create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_or_create_collection\u001b[39m(\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    225\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Collection:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_server\u001b[39m.\u001b[39;49mget_or_create_collection(\n\u001b[1;32m    227\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    228\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    229\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding_function,\n\u001b[1;32m    230\u001b[0m         data_loader\u001b[39m=\u001b[39;49mdata_loader,\n\u001b[1;32m    231\u001b[0m         tenant\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtenant,\n\u001b[1;32m    232\u001b[0m         database\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatabase,\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m trace_granularity \u001b[39m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/segment.py:216\u001b[0m, in \u001b[0;36mSegmentAPI.get_or_create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, tenant, database)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39m@trace_method\u001b[39m(\n\u001b[1;32m    202\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSegmentAPI.get_or_create_collection\u001b[39m\u001b[39m\"\u001b[39m, OpenTelemetryGranularity\u001b[39m.\u001b[39mOPERATION\n\u001b[1;32m    203\u001b[0m )\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     database: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Collection:\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_collection(  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    217\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    218\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    219\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding_function,\n\u001b[1;32m    220\u001b[0m         data_loader\u001b[39m=\u001b[39;49mdata_loader,\n\u001b[1;32m    221\u001b[0m         get_or_create\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    222\u001b[0m         tenant\u001b[39m=\u001b[39;49mtenant,\n\u001b[1;32m    223\u001b[0m         database\u001b[39m=\u001b[39;49mdatabase,\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m trace_granularity \u001b[39m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/segment.py:190\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_product_telemetry_client\u001b[39m.\u001b[39mcapture(\n\u001b[1;32m    183\u001b[0m     ClientCreateCollectionEvent(\n\u001b[1;32m    184\u001b[0m         collection_uuid\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m),\n\u001b[1;32m    185\u001b[0m         embedding_function\u001b[39m=\u001b[39membedding_function\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    187\u001b[0m )\n\u001b[1;32m    188\u001b[0m add_attributes_to_current_span({\u001b[39m\"\u001b[39m\u001b[39mcollection_uuid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m)})\n\u001b[0;32m--> 190\u001b[0m \u001b[39mreturn\u001b[39;00m Collection(\n\u001b[1;32m    191\u001b[0m     client\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    192\u001b[0m     \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mcoll[\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    193\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    194\u001b[0m     metadata\u001b[39m=\u001b[39;49mcoll[\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m],  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    195\u001b[0m     embedding_function\u001b[39m=\u001b[39;49membedding_function,\n\u001b[1;32m    196\u001b[0m     data_loader\u001b[39m=\u001b[39;49mdata_loader,\n\u001b[1;32m    197\u001b[0m     tenant\u001b[39m=\u001b[39;49mtenant,\n\u001b[1;32m    198\u001b[0m     database\u001b[39m=\u001b[39;49mdatabase,\n\u001b[1;32m    199\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/models/Collection.py:85\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, client, name, id, embedding_function, data_loader, tenant, database, metadata)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m# Check to make sure the embedding function has the right signature, as defined by the EmbeddingFunction protocol\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     validate_embedding_function(embedding_function)\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_loader \u001b[39m=\u001b[39m data_loader\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/types.py:210\u001b[0m, in \u001b[0;36mvalidate_embedding_function\u001b[0;34m(embedding_function)\u001b[0m\n\u001b[1;32m    207\u001b[0m protocol_signature \u001b[39m=\u001b[39m signature(EmbeddingFunction\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m function_signature \u001b[39m==\u001b[39m protocol_signature:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    211\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected EmbeddingFunction.__call__ to have the following signature: \u001b[39m\u001b[39m{\u001b[39;00mprotocol_signature\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mfunction_signature\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected EmbeddingFunction.__call__ to have the following signature: odict_keys(['self', 'input']), got odict_keys(['self', 'args', 'kwargs'])\nPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\nPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    \n",
    "    splits,\n",
    "    embedding\n",
    "\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count all embeddings in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btest3image/home/ubuntu/langchain-chat/01_PG_Draft_Outline.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(vectordb\u001b[39m.\u001b[39m_collection\u001b[39m.\u001b[39mcount())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectordb' is not defined"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using file metadata for better contextulization. Add a filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understanding embedding serach\n",
    "    - Similarity search\n",
    "    - Max marginal relevance search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"add some sample question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `k` is used to define number of docs to be returned, let us check the count of returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the content of the returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Persist the database for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "- Retrieval using similarity search\n",
    "- Max Marginal Query for similarity and introducing diversity in the returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrieval import similarity_serach\n",
    "\n",
    "ss = similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding context of page metadat and using self retrieval query using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
