{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- This is a summary program based on Langchain's short course 'Chat with your data'\n",
    "- A simplified version that uses PDF file only to show how a document is transformed\n",
    "    - Load multiple PDF files\n",
    "    - Split loaded files into smaller chunks\n",
    "    - Chunks are embedded using OpenAI embedding\n",
    "    - Store these embeddings in a Vector database (ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "\n",
    "import os,\n",
    "import sys,\n",
    "import openai\n",
    "\n",
    "from dotenv import get_dotenv, load_dot_env\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langchain provides a <loader> module for loading both structured and unstructured data sources. Here we are using PyPDF loader for uploading sample PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loader import PyPDFloader\n",
    "\n",
    "loaders = [\n",
    "\n",
    "PyPdfLoader(\"/docs/MachineLearning-Lecture01.pdf\"),\n",
    "PyPdfLoader(\"/docs/MachineLearning-Lecture02.pdf\"),\n",
    "PyPdfLoader(\"/docs/MachineLearning-Lecture03.pdf\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find out how many pages have been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Break uploaded PDFs into smaller chunks. We need to define, chunk size, chunk overlap. Langchain provides RecursiveCharacterTextSplitter and Character text splitter. Major difference is \n",
    "    - Recursive character text splitter - is preferred for Generic text splitting\n",
    "    - Character text splitter splits on new line character. If you set the character on space it will be split as recursive CTS\n",
    "    - double new line separater between paragraphs\n",
    "    - Recursive Character text splitters has other separators as well such /n/n, /n, \" \", \"\" by default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 120\n",
    "chunk_overlap = 10\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "\n",
    "r_splitter.split_text(\n",
    "\n",
    "    pages,\n",
    "    seperator =  \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore these chucks\n",
    "    - How many chunks?\n",
    "    - What is inside them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the text of a chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand Embeddings\n",
    "    - Use OpenAI embedding\n",
    "    - Understand similarity between words and sentences\n",
    "    - Use `dot` product to compare embeddings, higher score is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAI.Embeddings\n",
    "embedding = OpenAI.Embeddings()\n",
    "\n",
    "embedding_1 = embed_query('I go to school')\n",
    "\n",
    "embedding_2 = embed_query('I go to my class')\n",
    "\n",
    "embedding_3 = embed_query('I love playing football ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedding_1, embedding_1)\n",
    "np.dot(embedding_1, embedding_2)\n",
    "np.dot(embedding_1, embedding_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup a vector database to store all splits after embedding them\n",
    "    - Run `pip install chromadb`\n",
    "    - Need to create a directory where all splits will be stored and pass it as persist_path\n",
    "    - Need to pass embedding information, we are using OpenAI embeddings\n",
    "    - All splits as document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vector_database import Chroma\n",
    "\n",
    "\n",
    "\n",
    "persist_directory='docs/chroma'\n",
    "\n",
    "# remove any existing directory\n",
    "!rm -rf ./docs/chroma\n",
    "\n",
    "# setup chroma db\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    persist_directory=persist_directory,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count all embeddings in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector_db._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using file metadata for better contextulization. Add a filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understanding embedding serach\n",
    "    - Similarity search\n",
    "    - Max marginal relevance search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"add some sample question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `k` is used to define number of docs to be returned, let us check the count of returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the content of the returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Persist the database for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "- Retrieval using similarity search\n",
    "- Max Marginal Query for similarity and introducing diversity in the returned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrieval import similarity_serach\n",
    "\n",
    "ss = similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding context of page metadat and using self retrieval query using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
